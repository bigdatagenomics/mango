#!/usr/bin/env bash

set -e -x -v

# make a tempdir for writing maven cruft to
MANGO_MVN_TMP_DIR=$(mktemp -d -t mangoTestMvnXXXXXXX)

# add this tempdir to the poms...
find . -name pom.xml \
    -exec sed -i.bak \
    -e "s:sun.io.serialization.extendedDebugInfo=true:sun.io.serialization.extendedDebugInfo=true -Djava.io.tmpdir=${MANGO_MVN_TMP_DIR}:g" \
    {} \;
find . -name "*.bak" -exec rm {} \;

# variable declarations
export PATH=${JAVA_HOME}/bin/:${PATH}
export MAVEN_OPTS="-Xmx1536m -XX:MaxPermSize=1g -Dfile.encoding=utf-8"
DIR=$( cd $( dirname ${BASH_SOURCE[0]} ) && pwd )
PROJECT_ROOT=${DIR}/..
VERSION=$(grep "<version>" ${PROJECT_ROOT}/pom.xml  | head -2 | tail -1 | sed 's/ *<version>//g' | sed 's/<\/version>//g')

# is the hadoop version set?
if ! [[ ${HADOOP_VERSION} ]];
then
    echo "HADOOP_VERSION environment variable is not set."
    echo "Please set this variable before running."

    exit 1
fi

# is the spark version set?
if ! [[ ${SPARK_VERSION} ]];
then
    echo "SPARK_VERSION environment variable is not set."
    echo "Please set this variable before running."

    exit 1
fi


# this next line is supposed to fail
set +e

echo "Rewriting POM.xml files to Scala 2.10 and Spark 1 should error..."
./scripts/move_to_spark_1.sh
if [[ $? == 0 ]];
then
    echo "Running move_to_spark_1.sh when POMs are set up for Spark 1 should fail, but error code was 0 (success)."
    exit 1
fi

./scripts/move_to_scala_2.10.sh
if [[ $? == 0 ]];
then
    echo "Running move_to_scala_2.10.sh when POMs are set up for Scala 2.10 should fail, but error code was 0 (success)."
    exit 1
fi

set -e

# are we testing for spark 2.0.0? if so, we need to rewrite our poms first
if [ ${SPARK_VERSION} == 2.0.0 ];
then

    echo "Rewriting POM.xml files for Spark 2."
    ./scripts/move_to_spark_2.sh

    # shouldn't be able to move to spark 2 twice
    set +e
    ./scripts/move_to_spark_2.sh
    if [[ $? == 0 ]];
    then
        echo "We have already moved to Spark 2, so running move_to_spark_2.sh a second time should fail, but error code was 0 (success)."
        exit 1
    fi
    set -e
fi

# are we testing for scala 2.11? if so, we need to rewrite our poms to 2.11 first
if [ ${SCALAVER} == 2.11 ];
then
    echo "Rewriting POM.xml files for Scala 2.11."
    ./scripts/move_to_scala_2.11.sh

    # shouldn't be able to move to scala 2.11 twice
    set +e
    ./scripts/move_to_scala_2.11.sh
    if [[ $? == 0 ]];
    then
        echo "We have already moved to Scala 2.11, so running move_to_scala_2.11.sh a second time should fail, but error code was 0 (success)."
        exit 1
    fi
    set -e
fi

# print versions
echo "Testing MANGO version ${VERSION} on Spark ${SPARK_VERSION} and Hadoop ${HADOOP_VERSION}"

# clean the targets first
mvn clean

# if this is a pull request, we need to set the coveralls pr id
if [[ ! -z $ghprbPullId ]];
then
    COVERALLS_PRB_OPTION="-DpullRequest=${ghprbPullId}"
fi

# coveralls token should not be visible
set +x +v

if [[ -z ${COVERALLS_REPO_TOKEN} ]];
then
    echo "Coveralls token is not set. Exiting..."
    exit 1
fi

# if those pass, build the distribution package and the integration tests
mvn -U \
    test \
    -P coverage,coveralls  scoverage:report coveralls:report \
    -DrepoToken=${COVERALLS_REPO_TOKEN} ${COVERALLS_PRB_OPTION}

# make verbose again
set -x -v

# first, build the sources, run the unit tests
mvn clean package \
    -Dhadoop.version=${HADOOP_VERSION} \
    -Dspark.version=${SPARK_VERSION} \
    -DargLine=${MANGO_MVN_TMP_DIR}

# we are done with maven, so clean up the maven temp dir
find ${MANGO_MVN_TMP_DIR}
rm -rf ${MANGO_MVN_TMP_DIR}

# and move our poms back to their original values
if [ ${SPARK_VERSION} == 2.0.0 ];
then

    echo "Rewriting POM.xml files back to Spark 1."
    ./scripts/move_to_spark_1.sh
fi
if [ ${SCALAVER} == 2.11 ];
then
    echo "Rewriting POM.xml files back to Scala 2.10."
    ./scripts/move_to_scala_2.10.sh
fi
echo
echo "All the tests passed"
echo
